# ğŸ”¬ Functional-Group Atlas for Interface Programming

[![Python](https://img.shields.io/badge/Python-3.10%2B-blue.svg)](https://www.python.org/)
[![License](https://img.shields.io/badge/license-MIT-green.svg)](https://opensource.org/licenses/MIT)
[![Status](https://img.shields.io/badge/status-active-brightgreen.svg)]()

This repository provides a **reproducible, modular machine-learning workflow** for building a **data-driven functional-group atlas** that enables *predictable programming* of **carbonâ€“molten salt interfacial wettability and heat transport** for thermal energy storage.

The core idea is to **deconstruct functional-group effects into two orthogonal feature dimensions**:

- **Elemental / bonding descriptors** â†’ dominate *interfacial wettability* (quantified by adsorption/binding affinity, **Eb**).
- **Geometric / topological descriptors** â†’ dominate *interfacial heat transport potential* (quantified by low-frequency phonon spectral matching, **NVOA**).

This repo focuses on the **machine-learning part of the workflow**: hierarchical feature engineering, Bayesian hyperparameter optimization, stacking ensemble construction, rigorous repeated cross-validation, SHAP-based interpretation (including a **Two-Level Weighted SHAP** strategy), and high-throughput prediction for a broader candidate space.

---

## ğŸš€ Key Features

- **Dual-Target Learning (Eb & NVOA)** ğŸ¯  
  Train and interpret **two independent models** for interfacial wettability (Eb) and thermal transport potential (NVOA).

- **Hierarchical Feature Engineering** ğŸ› ï¸  
  A rigorous three-stage selection strategy:
  1) **Filter**: remove highly correlated features (Pearson threshold) using **Mutual Information** (default) or Pearson-to-target criterion  
  2) **Embedded**: SHAP-driven coarse screening with a Random Forest  
  3) **Wrapper**: SHAP-driven recursive elimination with **early stopping** to locate the optimal feature set

- **Efficient Bayesian Hyperparameter Optimization** âš¡  
  Uses Bayesian optimization (scikit-optimize) to tune multiple tree-based regressors efficiently.

- **High-Performance Stacking Ensemble** ğŸ§   
  Builds a two-layer stacking model:
  - **Level-0**: heterogeneous tree learners (e.g., RF/ETR/GBRT/HGBR/XGB/LGBM/CBR)
  - **Level-1 meta-learner**: **ElasticNet** (regularized linear combiner)

- **Rigorous Robustness Evaluation** ğŸ”  
  Repeated evaluation across many random seeds (default **100**) with outer K-fold CV, reducing split-induced contingencies.

- **Interpretable â€œTwo-Level Weighted SHAPâ€** ğŸ“Š  
  Produces a more stable global importance ranking by weighting:
  - within-fold SHAP by **1/RMSE of base learners**
  - across folds by **1/RMSE of stacking meta-learner**

- **One-Click Prediction for New Candidates** ğŸ§ª  
  Predict Eb/NVOA for unseen functional-group candidates from an Excel sheet, exporting full results to Excel/CSV.

---

## ğŸ“‚ Repository Structure

```
.
â”œâ”€â”€ Feature engineering-FGA.ipynb             #ğŸ“œ [Step 1] Feature Selection & Dataset Generation
â”œâ”€â”€ Tree_stacking-FGA.ipynb                   #ğŸ“œ [Step 2 & 3] Optimization, Stacking, SHAP, Prediction
â”‚
â”œâ”€â”€ Original database-FGA.xlsx                #ğŸ“„ (User-provided) Raw feature database with BOTH targets (Eb & NVOA)
â”œâ”€â”€ Final_engineered_dataset-FGA-Eb.xlsx      #ğŸ“„ (Generated/renamed) Feature-engineered dataset for Eb
â”œâ”€â”€ Final_engineered_dataset-FGA-NVOA.xlsx    #ğŸ“„ (Generated/renamed) Feature-engineered dataset for NVOA
â”œâ”€â”€ prediction-FGA-Eb.xlsx                    #ğŸ“„ (User-provided) Prediction set for Eb (features only)
â”œâ”€â”€ prediction-FGA-NVOA.xlsx                  #ğŸ“„ (User-provided) Prediction set for NVOA (features only)
â”‚
â”œâ”€â”€ environment.yml                           # ğŸ“¦ Conda environment config for cross-platform setup
â”œâ”€â”€ requirements.txt                          # ğŸ“¦ Pip dependencies for basic/non-Conda setup
â”œâ”€â”€ spec-file.txt                             # ğŸ“¦ Exact Conda config for highest-fidelity reproducibility (Win x64)
â”‚
â”œâ”€â”€ LICENSE                                   # ğŸ“œ The MIT License file
â””â”€â”€ README.md                                 # ğŸ—ºï¸ The document you are currently reading
```

## ğŸ—ºï¸ The Workflow

**`Script A: Feature Engineering`**  
*Compress the descriptor space and generate optimized datasets*

`â¬‡ï¸`

**`Script B-1: Hyperparameter Optimization`**  
*Bayesian optimization for enabled base learners*

`â¬‡ï¸`

**`Script B-2: Stacking Ensemble + Evaluation + SHAP`**  
*OOF stacking + repeated CV + Two-Level Weighted SHAP exports*

`â¬‡ï¸`

**`Script B-3: Prediction`**  
*Apply trained stacking model to unseen candidates and export results*

---

## ğŸ“œ Script A: Feature Engineering (`Feature engineering-FGA.ipynb`)

### ğŸ¯ What it does
- Loads `Original database-FGA.xlsx`
- Extracts features by slice and selects the target by column index
- Runs a 3-stage feature selection pipeline:
  - **Stage 1 (Filter)**: Pearson correlation pruning (default threshold `0.8`) using **Mutual Information** to decide which feature to keep in a correlated pair
  - **Stage 2 (Embedded)**: Random Forest + SHAP coarse screening (default keep top `80%`)
  - **Stage 3 (Wrapper)**: SHAP-guided iterative elimination with **early stopping** (default patience `50`)

### âœ… Default configuration (edit at top of notebook)
- `INPUT_FILE = 'Original database-FGA.xlsx'`
- `OUTPUT_DIR = 'feature_engineering_output'`
- `FEATURE_COLUMN_SLICE = '1:-2'`  (features exclude last two cols)
- `TARGET_COLUMN_INDEX = -1`       (choose last col as target by default)
- `FILTER_METHOD_CRITERION = 'mutual_info'`
- `PEARSON_CORR_THRESHOLD = 0.8`

### â–¶ï¸ How to run for **both targets**
Run the notebook twice:

1. **For NVOA**
   - keep `TARGET_COLUMN_INDEX = -1`
   - run all cells â†’ get `feature_engineering_output/Final_Selected_Dataset_*.xlsx`
   - rename to `Final_engineered_dataset-FGA-NVOA.xlsx`

2. **For Eb**
   - set `TARGET_COLUMN_INDEX = -2`
   - run all cells â†’ get another `Final_Selected_Dataset_*.xlsx`
   - rename to `Final_engineered_dataset-FGA-Eb.xlsx`

### ğŸ“„ Outputs
All outputs go to `feature_engineering_output/`, including:

- correlation matrices at different stages
- process summary Excel
- iterative performance history Excel
- **Final selected dataset** (core output):  
  `Final_Selected_Dataset_YYYYMMDD_HHMMSS.xlsx`

---

## ğŸ“œ Script B: Training / Evaluation / Prediction (`Tree_stacking-FGA.ipynb`)

> âš ï¸ IMPORTANT: This notebook contains **three sequential parts** (B-1/B-2/B-3).  
> **Run them in the same session** so variables (e.g., `grid_searches`) are available downstream.

---

### ğŸ“œ Script B-1: Hyperparameter Optimization (Bayesian)

#### ğŸ¯ What it does
- Loads engineered dataset (Eb *or* NVOA)
- Tunes enabled base learners using Bayesian optimization
- Stores results in memory: `grid_searches`

#### âœ… Key parameters (cell header)
- `EXCEL_FILE_PATH = 'Final_engineered_dataset-FGA-Eb.xlsx'` *(switch to NVOA file when needed)*
- `X_COLS_SLICE = slice(1, -1)` and `Y_COLS_SLICE = -1`
- `CV_N_SPLITS = 10`
- `N_ITER_BAYESIAN = 30`
- `ENABLED_MODELS = [...]` (choose which models to optimize)

---

### ğŸ“œ Script B-2: Stacking Ensemble + Evaluation + Two-Level Weighted SHAP

#### ğŸ¯ What it does
- Filters `grid_searches` to keep enabled base learners
- Builds OOF predictions and trains **ElasticNet** meta-learner
- Repeats outer CV across many seeds for stability (default `100`)
- Computes:
  - per-fold metrics tables
  - Two-Level Weighted SHAP global importance
  - SHAP swarm data export

#### âœ… Key parameters
- `N_SEEDS_FOR_EVALUATION = 100`
- `N_SPLITS_OUTER_CV = 10`
- `META_LEARNER_N_ITER_BAYESIAN = 50`
- `OUTPUT_EXCEL_FILENAME = 'SHAP_Analysis_Results.xlsx'`
- `WEIGHTING_METHOD = '1/RMSE'`
- `N_FEATURES_TO_PLOT = 30`
- `PLOT_SHAP_SWARM_PLOT = True`

#### ğŸ“„ Outputs (main)
- `SHAP_Analysis_Results.xlsx` with multiple sheets, e.g.:
  - `{Model}_GlobalImportance`
  - `{Model}_SwarmPlotData`
  - `Fold_Performance_Metrics`
  - `Global_Importance_Summary`

> The notebook also displays SHAP beeswarm + bar plots inline.

---

### ğŸ“œ Script B-3: Prediction (Unseen candidates)

#### ğŸ¯ What it does
- Loads prediction features from Excel
- Aligns feature columns to training set
- Predicts using base learners + final stacking model
- Exports timestamped results

#### âœ… Key parameters
- `UNKNOWN_DATA_FILE = 'prediction-FGA-Eb.xlsx'` *(switch to NVOA file when needed)*
- `UNKNOWN_DATA_FILE_COLUMN_RANGE = (slice(None), slice(1, None))` *(skip ID column)*
- `REUSE_PRETRAINED_STACKING_MODEL = False`
  - `False`: retrain a final model and predict (more self-contained)
  - `True`: reuse trained model from the evaluation step (faster)
- `PREDICTION_OUTPUT_FILENAME_PREFIX = 'unknown_predictions'`
- `PREDICTION_EXPORT_TO_EXCEL = True`

#### ğŸ“„ Outputs
- `unknown_predictions_YYYYMMDD_HHMMSS.xlsx` (and/or `.csv`)
  - includes stacking prediction + per-base-learner predictions for analysis

---

## ğŸ’» How to Use (Quickstart)

### 1) Environment setup
~~~bash
pip install -r requirements.txt
~~~

### 2) Feature engineering (run twice)
- Open `Feature engineering-FGA.ipynb`
- Set:
  - for **NVOA**: `TARGET_COLUMN_INDEX = -1`
  - for **Eb**:   `TARGET_COLUMN_INDEX = -2`
- Run all cells each time
- Rename the produced `Final_Selected_Dataset_*.xlsx` to:
  - `Final_engineered_dataset-FGA-NVOA.xlsx`
  - `Final_engineered_dataset-FGA-Eb.xlsx`

### 3) Train + evaluate + interpret + predict (run twice)
- Open `Tree_stacking-FGA.ipynb`
- For **Eb** run:
  - `EXCEL_FILE_PATH = 'Final_engineered_dataset-FGA-Eb.xlsx'`
  - `UNKNOWN_DATA_FILE = 'prediction-FGA-Eb.xlsx'`
- For **NVOA** run:
  - `EXCEL_FILE_PATH = 'Final_engineered_dataset-FGA-NVOA.xlsx'`
  - `UNKNOWN_DATA_FILE = 'prediction-FGA-NVOA.xlsx'`

Run the notebook **top to bottom** to finish B-1 â†’ B-2 â†’ B-3.

---

## ğŸ“¦ Environment Setup & Reproducibility

### ğŸ Python Version
This project was developed and tested using **Python 3.10.18**. While it may work with other Python 3.10+ versions, using this specific version is recommended to maximize reproducibility.

---

### ğŸ“‹ Core Dependencies
Below are the core scientific computing and machine learning libraries used in this project.

~~~
# Core scientific computing and machine learning libraries
pandas==2.2.2
numpy==1.26.4
matplotlib==3.8.4
seaborn==0.13.2
scikit-learn==1.6.1
xgboost==3.0.2
catboost==1.2.7
lightgbm==4.6.0
scikit-optimize==0.10.2
shap==0.48.0
umap-learn==0.5.7
tqdm==4.67.1
openpyxl==3.1.5

# Libraries for Jupyter Notebook integration
jupyterlab>=4.0.0
notebook==7.3.2
ipykernel==6.29.5
ipywidgets==8.1.7
~~~

---

### Environment Configuration

---

### Environment Configuration

**âš ï¸ IMPORTANT NOTE:** For academic review or users who need to reproduce the results from our paper as closely as possible, **it is highly recommended to use Option 1**. Using Option 2 or 3 is more likely to produce numerical differences in the output, even with identical code and random seeds. This is primarily due to the following reasons:

1.  **Dependency Solver Ambiguity** ğŸ§©: `environment.yml` and `requirements.txt` files allow the dependency solver (Conda or Pip) to select different versions of underlying sub-dependencies over time.
2.  **Platform-Specific Builds** ğŸ’»: Even with identical package versions, the underlying compiled libraries (e.g., Intel MKL vs. OpenBLAS) can differ across operating systems, causing minute variations in floating-point calculations.
3.  **Sensitivity of Stochastic Optimization** ğŸ²: This project utilizes Bayesian Optimization. The minor computational variations from the points above can influence the optimization trajectory, leading to different hyperparameter choices and, consequently, different final results.
4.  **Stochasticity from Parallel Computing** âš¡: To accelerate computations, the script may utilize parallel processing (e.g., via `n_jobs=-1`). However, when computations are executed across multiple CPU cores, the precise order of floating-point operations can vary slightly, which can be amplified by iterative algorithms.

### ğŸ¥‡ Option 1: Highest-Fidelity Reproducibility (via `spec-file.txt`)
**Platform:** Windows (x64)

~~~bash
conda create --name my-project-env --file spec-file.txt
conda activate my-project-env
~~~

---

### ğŸ¥ˆ Option 2: Cross-Platform Setup (via `environment.yml`)
~~~bash
conda env create -f environment.yml -n my-project-env
conda activate my-project-env
~~~

---

### ğŸ¥‰ Option 3: Basic Setup (via `requirements.txt`)
~~~bash
python -m venv venv
# Windows:
# venv\Scripts\activate
# Linux/macOS:
# source venv/bin/activate
pip install -r requirements.txt jupyterlab
~~~

---

## ğŸ“œ License and Correspondence

The code in this repository is released under the **MIT License** (see `LICENSE`).

For any inquiries or if you use this workflow in your research, please correspond with:  
Prof. [Guangmin Zhou](mailto:guangminzhou@sz.tsinghua.edu.cn) ğŸ“§.
ğŸ“§ 

---

## ğŸ™ Acknowledgements

[Yifei Zhu](zhuyifeiedu@126.com) at Tsinghua University conceived and formulated the algorithms, built the quantum chemistry database, developed and deposited the code, and authored this comprehensive guideline document.


